{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 2D CNNs and Image Preprocessing to read ECG graphs and perform PVC diagnosis\n",
    "\n",
    "By Lee Lip Tong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pytesseract\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, Dropout,MaxPool2D, ELU, BatchNormalization\n",
    "import pickle\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process image takes an image and splits it into slices which are positioned around each blue line\n",
    "def process_image(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    graph = isolate_graph(img)\n",
    "    graph = cv2.blur(graph,(3,3))\n",
    "    ret,graph = cv2.threshold(graph,240,255,cv2.THRESH_BINARY)\n",
    "    pulselines = get_pulse_lines(img)\n",
    "    print(len(pulselines))\n",
    "    labels = get_pulse_strings(img,pulselines)\n",
    "    top, bottom, number = extract_horizontal_lines(img)\n",
    "    scalingfactor=(bottom-top)/(number-1)\n",
    "    left, right, hnum = get_precalculated_values()\n",
    "    hinterval=(right-left)/(hnum-1)\n",
    "    lrcrop=0.4/0.2\n",
    "    rrcrop=0.6/0.2\n",
    "    sliced_image_width = int((lrcrop+rrcrop)*hinterval)\n",
    "    filename=filepath[6:-4]\n",
    "    filenamelist=[filename]*len(pulselines)\n",
    "    idlist=range(0,len(pulselines))\n",
    "    if os.path.isdir('train_processed/{}'.format(filename))!= True:\n",
    "        os.mkdir('train_processed/{}'.format(filename))\n",
    "    with open('text_processed/{}.txt'.format(filename), 'wb') as file:\n",
    "        pickle.dump([pulselines,labels,filenamelist,idlist], file)\n",
    "    for i, x in enumerate(pulselines):\n",
    "        leftcrop = int(x - lrcrop*hinterval)\n",
    "        rightcrop= int(x+ rrcrop*hinterval)\n",
    "        blankimage=np.zeros((img.shape[0],sliced_image_width), np.uint8)\n",
    "        blankimage=cv2.bitwise_not(blankimage)\n",
    "        if leftcrop >= 0 and rightcrop <= right:\n",
    "            cropimage=graph[0:img.shape[0], leftcrop:rightcrop]\n",
    "        if leftcrop < 0 :\n",
    "            cropimage=blankimage\n",
    "            cropimage[0:img.shape[0],-leftcrop:(rightcrop-leftcrop)]=graph[0:img.shape[0],0:rightcrop]\n",
    "        if rightcrop > right:\n",
    "            cropimage=blankimage\n",
    "            cropimage[0:img.shape[0],0:(right-leftcrop)]=graph[0:img.shape[0],leftcrop:right]\n",
    "\n",
    "        cropimage=cv2.resize(cropimage,(128,128))\n",
    "        \n",
    "        cv2.imwrite('train_processed/{}/{}.png'.format(filename,i), cropimage)\n",
    "    \n",
    "    return pulselines, labels, filenamelist, idlist\n",
    "        \n",
    "def process_test_image(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    graph = isolate_graph(img)\n",
    "    graph = cv2.blur(graph,(3,3))\n",
    "    ret,graph = cv2.threshold(graph,240,255,cv2.THRESH_BINARY)\n",
    "    pulselines = get_pulse_lines(img)\n",
    "    print(len(pulselines))\n",
    "    labels = get_pulse_strings(img,pulselines)\n",
    "    top, bottom, number = extract_horizontal_lines(img)\n",
    "    scalingfactor=(bottom-top)/(number-1)\n",
    "    left, right, hnum = get_precalculated_values()\n",
    "    hinterval=(right-left)/(hnum-1)\n",
    "    lrcrop=0.4/0.2\n",
    "    rrcrop=0.6/0.2\n",
    "    sliced_image_width = int((lrcrop+rrcrop)*hinterval)\n",
    "    filename=filepath[5:-4]\n",
    "    filenamelist=[filename]*len(pulselines)\n",
    "    idlist=range(0,len(pulselines))\n",
    "    if os.path.isdir('test_processed/{}'.format(filename))!= True:\n",
    "        os.mkdir('test_processed/{}'.format(filename))\n",
    "    with open('test_text_processed/{}.txt'.format(filename), 'wb') as file:\n",
    "        pickle.dump([pulselines,labels,filenamelist,idlist], file)\n",
    "    for i, x in enumerate(pulselines):\n",
    "        leftcrop = int(x - lrcrop*hinterval)\n",
    "        rightcrop= int(x+ rrcrop*hinterval)\n",
    "        blankimage=np.zeros((img.shape[0],sliced_image_width), np.uint8)\n",
    "        blankimage=cv2.bitwise_not(blankimage)\n",
    "        if leftcrop >= 0 and rightcrop <= right:\n",
    "            cropimage=graph[0:img.shape[0], leftcrop:rightcrop]\n",
    "        if leftcrop < 0 :\n",
    "            cropimage=blankimage\n",
    "            cropimage[0:img.shape[0],-leftcrop:(rightcrop-leftcrop)]=graph[0:img.shape[0],0:rightcrop]\n",
    "        if rightcrop > right:\n",
    "            cropimage=blankimage\n",
    "            cropimage[0:img.shape[0],0:(right-leftcrop)]=graph[0:img.shape[0],leftcrop:right]\n",
    "\n",
    "        cropimage=cv2.resize(cropimage,(128,128))\n",
    "        \n",
    "        cv2.imwrite('test_processed/{}/{}.png'.format(filename,i), cropimage)\n",
    "    \n",
    "    return pulselines, labels, filenamelist, idlist\n",
    "        \n",
    "        \n",
    "#Extraction function for grid lines\n",
    "def extract_horizontal_lines(image):\n",
    "    lower = np.array([148, 148, 255], dtype = \"uint8\")\n",
    "    upper = np.array([195, 195, 255], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    img2 = cv2.bitwise_and(image, image, mask = mask)\n",
    "    gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.blur(gray,(12,12))\n",
    "    edges = cv2.Canny(blur, 80, 120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 300, 20)\n",
    "    blankimage = np.zeros((image.shape[0],image.shape[1],1), np.uint8)\n",
    "    for liner in lines:\n",
    "        for line in liner:\n",
    "            pt1 = (0,line[1])\n",
    "            pt2 = (image.shape[1],line[1])\n",
    "            cv2.line(blankimage, pt1, pt2, (255), 15)       \n",
    "\n",
    "    edges = cv2.Canny(blankimage, 80, 120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 300, 20)\n",
    "\n",
    "    linelist = []\n",
    "    for line in lines:\n",
    "        for lm in line:\n",
    "            linelist.append(lm[1])\n",
    "    linelist.sort()\n",
    "    linecentre=[sum(linelist[i:i+2])//2 for i in range(0,len(linelist),2)]\n",
    "\n",
    "    return linecentre[0], linecentre[-1], len(linecentre)\n",
    "\n",
    "def get_precalculated_values():\n",
    "    return 33, 7487, 101\n",
    "\n",
    "#Extraction function for grid lines\n",
    "def extract_vertical_lines(image):\n",
    "    lower = np.array([148, 148, 255], dtype = \"uint8\")\n",
    "    upper = np.array([195, 195, 255], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    img2 = cv2.bitwise_and(image, image, mask = mask)\n",
    "    gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.blur(gray,(5,5))\n",
    "\n",
    "\n",
    "    edges = cv2.Canny(blur, 80, 120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 300, 20)\n",
    "    blankimage = np.zeros((image.shape[0],image.shape[1],1), np.uint8)\n",
    "    for liner in lines:\n",
    "        for line in liner:\n",
    "            pt1 = (line[0],0)\n",
    "            pt2 = (line[0],image.shape[0])\n",
    "            cv2.line(blankimage, pt1, pt2, (255), 5)       \n",
    "\n",
    "    edges = cv2.Canny(blankimage, 80, 120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 300, 20)\n",
    "\n",
    "\n",
    "    linelist = []\n",
    "    for line in lines:\n",
    "        for lm in line:\n",
    "            linelist.append(lm[0])\n",
    "    linelist.sort()\n",
    "    linecentre=[sum(linelist[i:i+2])//2 for i in range(0,len(linelist),2)]\n",
    "    \n",
    "    return linecentre[0], linecentre[-1], len(linecentre)\n",
    "\n",
    "#Removes gridlines and any text from the graph\n",
    "def isolate_graph(image):\n",
    "    lower = np.array([0, 0, 0], dtype = \"uint8\")\n",
    "    upper = np.array([70, 70, 70], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    img2 = cv2.bitwise_and(image,image, mask = mask)\n",
    "    ret,gray = cv2.threshold(mask,0,255,cv2.THRESH_BINARY)\n",
    "    gray=cv2.bitwise_not(gray)\n",
    "    return gray\n",
    "\n",
    "#Gets the pixel location of blue/green pulse lines\n",
    "def get_pulse_lines(img):\n",
    "    lower = np.array([146, 113, 146], dtype = \"uint8\")\n",
    "    upper = np.array([255, 255, 148], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    img2 = cv2.bitwise_and(img, img, mask = mask)\n",
    "    gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 80, 120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 30, 1);\n",
    "    blankimage = np.zeros((img.shape[0],img.shape[1],1), np.uint8)\n",
    "    for liner in lines:\n",
    "        for line in liner:\n",
    "            pt1 = (line[0],0)\n",
    "            pt2 = (line[2],img.shape[1])\n",
    "            cv2.line(blankimage, pt1, pt2, (255), 1)       \n",
    "    edges = cv2.Canny(blankimage, 80,120)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/2, 2, None, 100, 20)\n",
    "    blankimage = np.zeros((img.shape[0],img.shape[1],1), np.uint8)\n",
    "    for liner in lines:\n",
    "        for line in liner:\n",
    "            pt1 = (line[0],0)\n",
    "            pt2 = (line[2],img.shape[1])\n",
    "            cv2.line(blankimage, pt1, pt2, (255), 10)       \n",
    "    linelist = []\n",
    "    for line in lines:\n",
    "        for lm in line:\n",
    "            linelist.append(lm[0])\n",
    "    linelist.sort()\n",
    "    linecentre=[sum(linelist[i:i+2])//2 for i in range(0,len(linelist),2)]\n",
    "    return linecentre\n",
    "\n",
    "#Gets the letters within the pulse strings\n",
    "def get_pulse_strings(image, pulselines):\n",
    "    cropimage=image[0:90,0:image.shape[1] ]\n",
    "    lower = np.array([0, 0, 0], dtype = \"uint8\")\n",
    "    upper = np.array([255, 128, 0], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(cropimage, lower, upper)\n",
    "    img2 = cv2.bitwise_and(cropimage, cropimage, mask = mask)\n",
    "    gray=cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv2.bitwise_not(gray)\n",
    "    ret,gray = cv2.threshold(gray,240,255,cv2.THRESH_BINARY)\n",
    "    text=[]\n",
    "\n",
    "    for i,line in enumerate(pulselines):\n",
    "        current=cv2.Canny(gray[10:80, line-15:line+15],100,200)\n",
    "        text.append(pytesseract.image_to_string(current,lang='eng',config='-c tessedit_char_whitelist=NVP-+RA -psm 10'))\n",
    "    return text\n",
    "\n",
    "#converts pixel distance to time\n",
    "def pxtotime(px):\n",
    "    left,right,number = get_precalculated_values()\n",
    "    interval=(right-left)/(number-1)\n",
    "    time=(px-left)/interval*0.2\n",
    "    return round(time,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "Run this once to preprocess training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir=\"train/\"\n",
    "trainlist= os.listdir(traindir)\n",
    "pulselist=[]\n",
    "pulsetext=[]\n",
    "pulseloc=[]\n",
    "pulseid=[]\n",
    "for i,file in enumerate(trainlist):\n",
    "    plist, ptext, ploc, pid = process_image(traindir+file)\n",
    "    pulselist+=plist\n",
    "    pulsetext+=ptext\n",
    "    pulseloc+=ploc\n",
    "    pulseid+=pid\n",
    "    print('Processed Images for {}, {} / {}'.format(file, i+1,len(trainlist)))\n",
    "    \n",
    "with open('data_processed.txt', 'wb') as file:\n",
    "        pickle.dump([pulselist, pulsetext, pulseloc, pulseid], file)\n",
    "        \n",
    "        \n",
    "traindir=\"test/\"\n",
    "trainlist= os.listdir(traindir)\n",
    "pulselist=[]\n",
    "pulsetext=[]\n",
    "pulseloc=[]\n",
    "pulseid=[]\n",
    "for i,file in enumerate(trainlist):\n",
    "    print('opening {}, {} / {}'.format(file, i+1,len(trainlist)))\n",
    "    plist, ptext, ploc, pid = process_test_image(traindir+file)\n",
    "    pulselist+=plist\n",
    "    pulsetext+=ptext\n",
    "    pulseloc+=ploc\n",
    "    pulseid+=pid\n",
    "    print('Processed Images for {}, {} / {}'.format(file, i+1,len(trainlist)))\n",
    "    \n",
    "with open('test_data_processed.txt', 'wb') as file:\n",
    "        pickle.dump([pulselist, pulsetext, pulseloc, pulseid], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Deep 2D CNN for classifying ECG beats\n",
    "This deep layered CNN is an adaptation of VGG16 as prescribed in this paper: https://arxiv.org/pdf/1804.06812.pdf\n",
    "Some code was adapted from: https://github.com/ankur219/ECG-Arrhythmia-classification/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=[128,128]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3),strides = (1,1), input_shape = IMAGE_SIZE +[3],kernel_initializer='glorot_uniform'))\n",
    "model.add(keras.layers.ELU())\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(keras.layers.ELU())\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2048))\n",
    "\n",
    "model.add(keras.layers.ELU())\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We train the model for 100 Epochs and observe 5 different measures: accuracy, precision, recall, PPV and specifity\n",
    "\n",
    "PPV or positive prediction value and specifity are the most important and we will decide to continue or stop training depending on their scores\n",
    "\n",
    "I attained around 98.7% PPV after training for 80 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "batch_size=64\n",
    "\n",
    "with open('data_processed.txt', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "train_data = data[0]\n",
    "print(len(train_data))\n",
    "test_name = data[2][-1025:-1]\n",
    "test_number = data[3][-1025:-1]\n",
    "test_label = data[1][-1025:-1]\n",
    "ytestlabels=[]\n",
    "for x in test_label:\n",
    "        ytestlabels+=[int(x=='V')]\n",
    "y_test_binary = to_categorical(ytestlabels, num_classes=2)\n",
    "test_image=[]\n",
    "for i in range(0,len(test_name)):\n",
    "        test_image.append(cv2.imread('train_processed/{}/{}.png'.format(test_name[i],test_number[i])))    \n",
    "test_image=np.array(test_image)\n",
    "\n",
    "number_of_batches= int(len(data[0][0:-1025]) / batch_size)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for index in range(number_of_batches):\n",
    "        #print('Loading data for Batch: {}/{}'.format(index+1, number_of_batches))\n",
    "        start = index*batch_size\n",
    "        end = start+batch_size\n",
    "        image_number=data[3][start:end]\n",
    "        image_name=data[2][start:end]\n",
    "        ylabels=[]\n",
    "        image_batch=[]\n",
    "        for x in data[1][start:end]:\n",
    "            ylabels+=[int(x=='V')]\n",
    "        y_binary = to_categorical(ylabels, num_classes=2)\n",
    "        for i in range(0,len(image_name)):\n",
    "            image_batch.append(cv2.imread('train_processed/{}/{}.png'.format(image_name[i],image_number[i])))\n",
    "        image_batch=np.array(image_batch)\n",
    "        loss = model.train_on_batch(image_batch,y_binary)\n",
    "\n",
    "    print('Loss for Epoch {}: {}'.format(epoch,loss))\n",
    "    yhat=model.predict(test_image)\n",
    "    Vtruth=y_test_binary[:,1]\n",
    "    Vresult=yhat[:,1]\n",
    "\n",
    "    correctscore=0\n",
    "    falsenegative=0\n",
    "    falsepositives=0\n",
    "    truepositives=0\n",
    "    truenegatives=0\n",
    "    for i in range(len(Vtruth)):\n",
    "        if Vtruth[i]==1 and Vresult[i]==1:\n",
    "            truepositives+=1\n",
    "        if Vtruth[i]==1 and Vresult[i]==0:\n",
    "            falsenegative+=1\n",
    "        if Vtruth[i]==0 and Vresult[i]==1:\n",
    "            falsepositives+=1\n",
    "        if Vtruth[i]==0 and Vresult[i]==0:\n",
    "            truenegatives+=1\n",
    "    accuracy=(truepositives+truenegatives)/(truepositives+truenegatives+falsepositives+falsenegative)\n",
    "    precision=truepositives/(truepositives+truenegatives)\n",
    "    recall=truepositives/(truepositives+falsenegative)\n",
    "    ppv=truepositives/(truepositives+falsepositives)\n",
    "    specifity=truenegatives/(falsepositives+truenegatives)\n",
    "    print('Validation Accuracy: {}, Precision :{}, Recall: {}, PPV:{}, specifity:{}'.format(accuracy,precision,recall,ppv,specifity))\n",
    "    if epoch %2 == 0:\n",
    "        model.save_weights('epoch s {}.h5'.format(epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions using trained model\n",
    "\n",
    "After training we then feed the testing data into our model to check its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data_processed.txt', 'rb') as file:\n",
    "        testdata = pickle.load(file)\n",
    "\n",
    "train_data = testdata[0]\n",
    "print(len(train_data))\n",
    "test_name = testdata[2]\n",
    "test_number = testdata[3]\n",
    "test_label = testdata[1]\n",
    "ytestlabels=[]\n",
    "for x in test_label:\n",
    "        ytestlabels+=[int(x=='V')]\n",
    "y_test_binary = to_categorical(ytestlabels, num_classes=2)\n",
    "test_image=[]\n",
    "for i in range(0,len(test_name)):\n",
    "        test_image.append(cv2.imread('test_processed/{}/{}.png'.format(test_name[i],test_number[i])))    \n",
    "test_image=np.array(test_image)\n",
    "\n",
    "yhattest=model.predict(test_image)\n",
    "\n",
    "predictions=yhattest[:,1]\n",
    "predictions=predictions.astype(int)\n",
    "\n",
    "with open('predictions.txt', 'wb') as file:\n",
    "        pickle.dump(predictions,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data_processed.txt', 'rb') as file:\n",
    "        testdata=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tplist=testdata[0]\n",
    "tploc=testdata[2]\n",
    "tpid=testdata[3]\n",
    "csvData=[['filename','Location of V beat']]\n",
    "\n",
    "for i in range(0,len(testdata[0])):\n",
    "    if predictions[i]==1:\n",
    "        csvData+=[['{}.png'.format(tploc[i]), pxtotime(tplist[i])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Vbeat Predictions.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csvData)\n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
